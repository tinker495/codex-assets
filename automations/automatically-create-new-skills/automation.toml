version = 1
id = "automatically-create-new-skills"
name = "Automatically create new skills"
prompt = "Review the last day of ~/.codex/sessions and detect skill-level operational noise. Before any analysis, set CODEX_HOME=${CODEX_HOME:-$HOME/.codex}, verify writability with test -w on destination parent directories, and run $CODEX_HOME/automations/automatically-create-new-skills/scripts/scan_noise.py to get deterministic JSON summary. Use only this scanner output for signal counts and skill attribution. Treat noise as HIGH when any listed signal appears >=2 times or in >=2 sessions. Signals: [quick_validate failure, frontmatter/YAML error, PyYAML install/run mention, ModuleNotFoundError: No module named 'yaml', No such file or directory, missing collect_branch_info.py, missing /shared/code-health, Error: unknown flag: --json, Error: unknown flag: --repo, Error: PRD file not found: prd.json, command not found: grepai, command not found: timeout, command not found: pdfinfo, fatal: not a git repository, Error: could not open a new TTY, jq: parse error, unable to resolve PR from current branch, can't create temp file for here document: operation not permitted, Sandbox(Denied, PermissionError: [Errno 1] Operation not permitted, blocked by policy], ls: /automations/automatically-create-new-skills, ERROR:xenon:block, ERROR:xenon:module, date: invalid argument 's' for -I, No module named pytest, failed to send request to Ollama, ERROR collecting, ModuleNotFoundError: No module named, write_stdin failed: stdin is closed]. If no HIGH signal, report 'no changes'. If HIGH exists, refine only skills in (scanner.high_noise_skills.after_recently_touched) and cap edits to 5 skills per run; also refine only path-sensitive automations. Keep edits minimal and update existing skills first. Guardrails: quote YAML frontmatter values containing ':'. Validation must run via uv run --with pyyaml python $CODEX_HOME/skills/.system/skill-creator/scripts/quick_validate.py <skill_dir>; retry once only, then stop and report on second failure. Before sed/cat/rg or script execution on specific paths, verify with test -f/test -d or rg --files -g. If path missing, report once and fallback to git log --since=1.week --name-only and git diff --stat when repo context is needed. Before git commands, verify git rev-parse --is-inside-work-tree. Avoid here-doc syntax and avoid rm -f/rm -rf cleanup. Retry identical failing command at most once before fallback. If tool rejects --json, rerun without --json and parse text. If gh rejects --repo, rerun without --repo and pass OWNER/REPO positionally. If jq parse fails, rerun without --jq/--json and parse plain text. If PR resolution fails, fallback to gh pr list --author @me --state open. If gh fails with /dev/tty, rerun once with GH_FORCE_TTY=0 GIT_TERMINAL_PROMPT=0 GH_PAGER=cat. If write_stdin failed: stdin is closed, rerun the command via exec_command with tty=true and reopen a fresh session instead of retrying write_stdin. If grepai is missing, use rg discovery and skip grepai-only steps. If Ollama embedding call fails, skip embedding steps and continue with rg/grep. If timeout is missing, rerun without timeout wrapper (or use gtimeout when available). If pdfinfo is missing, use Python PDF metadata fallback or skip pdfinfo-only checks with a note. Open an inbox item with HIGH signals, changed files, and rationale. Create a new skill only when no existing skill can absorb the pattern."
status = "PAUSED"
rrule = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR;BYHOUR=10;BYMINUTE=40"
cwds = ["/Users/mrx-ksjung/project/snk2501o-sinokor-placement-optimization", "/Users/mrx-ksjung/project/codex-skills"]
created_at = 1770210925008
updated_at = 1771334607624
